{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticating(credential):\n",
    "    logging('\\n\\nfunction>>>>>authenticating')\n",
    "     \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # credential         • <dictionary>                 ○ its keys will be used to authenticate\n",
    "        \n",
    "    \"\"\"\n",
    "    █▀█ █░█ ▀█▀\n",
    "    █▄█ █▄█ ░█░\n",
    "    \"\"\"\n",
    "        # api                • <class 'tweepy.api.API'>     ○ authenticated api\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(credential[\"api_key\"], credential[\"api_secret\"])\n",
    "    auth.set_access_token(credential[\"access_token\"], credential[\"access_token_secret\"])\n",
    "    \n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    print(type(api))\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_retweet_tweet(api,tweet,dict_tweets_info,searched_word):\n",
    "    logging('\\n\\nfunction>>>>>print_and_retweet_tweet')\n",
    "    \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # api                • <class 'tweepy.api.API'>    ○ authenticated api\n",
    "        # tweet              • <tweet object>              ○ one single tweet object and its attributes \n",
    "        # dict_tweets_info   • <dictionary>                ○ empty, to be filled with informations from this tweet object\n",
    "        # searched_word      • <string>                    ○ seeking term (will be used here to validate the inner of tweet content) \n",
    "    \n",
    "    \"\"\"\n",
    "    █▀█ █░█ ▀█▀\n",
    "    █▄█ █▄█ ░█░\n",
    "    \"\"\"\n",
    "        # -1           ○ didn't found the searched_word on tweet.text it self (maybe )\n",
    "        # -2           ○ japanese or korean\n",
    "        # -3           ○ you have already retweeted this Tweet\n",
    "        # -4           ○ RateLimitError\n",
    "        # -5           ○ you are the owner of this tweet\n",
    "        # -6           ○ tweet was made by the bot's account, we can't retweet stuff made by us \n",
    "        # dict         ○ in a valid situation, returns a populated dictionary containing this tweet's data \n",
    "\n",
    "    try: \n",
    "        logging('appending infos to dictionary')\n",
    "        dict_tweets_info['created_at'].append(str(tweet.created_at))\n",
    "        dict_tweets_info['tweet_ID'].append(str(tweet.id))\n",
    "        dict_tweets_info['user'].append(str(tweet.user.screen_name))\n",
    "        dict_tweets_info['tweet_content'].append((tweet.text))\n",
    "        dict_tweets_info['place'].append(str(tweet.place))\n",
    "        dict_tweets_info['language'].append(str(tweet.lang))\n",
    "        dict_tweets_info['source'].append(str(tweet.source_url).replace(\"http://twitter.com/download/\",\"\"))\n",
    "    \n",
    "        logging('----------------------------------------')\n",
    "        logging('collected informations')\n",
    "        logging('----------------------------------------')\n",
    " \n",
    "        logging('dict_tweets_info: \\n '+str(dict_tweets_info))\n",
    "        logging('----------------------------------------')\n",
    "        \n",
    "        # ----- starting filters ------\n",
    "        \n",
    "        logging('print_and_retweet_tweet(): better filtering BEFORE retweet')\n",
    "        string_tweet_content = \"\".join(dict_tweets_info['tweet_content'] )\n",
    "        if not searched_word in string_tweet_content.lower():\n",
    "            logging('NAO ACHOU NA STRING A PALAVRA BUSCADA: '+ searched_word)\n",
    "            # NO WAY it's gonna retweet something that has NOT 'zolpidem on it'\n",
    "            return -1\n",
    "\n",
    "        string_lang_content = \"\".join(dict_tweets_info['language'] )\n",
    "        if string_lang_content in ['ja','ko','und','fa','ar']:\n",
    "            logging('lingua proibida p dar RT')\n",
    "            # NO WAY it's gonna retweet something that is in japanese or korean\n",
    "            return -2\n",
    "        else:\n",
    "            logging('teoricamente nao esta em japones nem coreano, está em: '+string_lang_content )\n",
    "        \n",
    "        my_user_object = api.me()\n",
    "        if str(my_user_object.screen_name) == str(tweet.user.screen_name):\n",
    "            logging('this tweet was made by yourself using your bot profile or is an old RETWEET !!we wont retweet it again')\n",
    "            return -6\n",
    "        else:\n",
    "            logging('this user is not you! you: '+ str(my_user_object.screen_name) + ' VS the tweeter: '+ str(tweet.user.screen_name) +', that s great')\n",
    "        \n",
    "        logging('retweeting ←←←←←←←←←←←←←')\n",
    "        api.retweet(tweet.id)\n",
    "        logging('→→→→→→→→→→→→→ retweeted')\n",
    "        return dict_tweets_info\n",
    "    \n",
    "    except tweepy.TweepError as e: \n",
    "        if e.api_code == 327:\n",
    "            logging('You have already retweeted this Tweet')\n",
    "            return -3\n",
    "        \n",
    "    except tweepy.RateLimitError as e:\n",
    "        logging('Excedeu limite por tempo?')\n",
    "        logging('erro: '+str(e))\n",
    "        logging('DORMINDO POR QUINZE MINUTOS')\n",
    "        time.sleep(60 * 15)  # we supposedly saw a rate limit that is ignored after 15 min ??? so we should wait 15 min to retry \n",
    "        return -4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_and_updates_value(path,incrementa_contagem_de_falha=False,inicializar = False):\n",
    "    logging('\\n\\nfunction>>>>>write_json_and_updates_value')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_date = now.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # try to read from file\n",
    "    try:\n",
    "        with open(path) as json_file:\n",
    "            tweets_status = json.load(json_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    # write on file\n",
    "    # if our current date is the same, increase amount of tweets.\n",
    "    # if our current date is different, amount is ZERO !!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    if inicializar or tweets_status['current_date'] != current_date: \n",
    "        logging('different dates, OR initializing, so we need to change the current_date value and also turn into 0 all the values')\n",
    "        with open(path, 'w') as f:\n",
    "            try:\n",
    "                content = {\"current_date\": current_date,\n",
    "                           \"amount_of_tweets\": 0,\n",
    "                           \"total_amount_including_failure\":0}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "    else: \n",
    "        logging('same date!! so, just change the value of tweetts')\n",
    "        if not incrementa_contagem_de_falha:\n",
    "                logging('increases both keys , the including failure and the sucessed amounts')\n",
    "                #vai incrementtar o total com falhas tb + o total dos sucessos\n",
    "                tweets_status[\"amount_of_tweets\"] = tweets_status[\"amount_of_tweets\"]+1 \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)\n",
    "                    \n",
    "        elif incrementa_contagem_de_falha:\n",
    "                # vai incrementar SOMENTE chave com total de tweets, independente de ter falhado ou nao\n",
    "                logging('INCREMENTANDO CHAVE DE CONTAGEM TOTAL DE TWEETS')\n",
    "                     # increasing amount of the ones who failure \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_infos_to_csv(valid_tweet):\n",
    "    logging('\\n\\nfunction>>>>>exporting_infos_to_csv')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_directory = os.getcwd()  \n",
    "    timestamp = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\").replace(':',\"-\").replace(',','--').replace(\" \",\"\")\n",
    "\n",
    "    CSV_path = current_directory+'\\\\arquivos_bot\\\\dados_exportados\\\\dados_'+timestamp+'.csv'\n",
    "    logging('log path: '+str(CSV_path))\n",
    "\n",
    "    logging('dict_tweets_info : '+str(valid_tweet))\n",
    "\n",
    "    # pegando os valores do dicionario e jogando em lista pq senao ele da apend no dicionario inteiro, linha de key e depois linha de value PRA CADA tweet\n",
    "    lista_valores_atuais = []\n",
    "    for key, value in valid_tweet.items():\n",
    "        lista_valores_atuais.append(\"\".join(value))\n",
    "\n",
    "    # forcing Tweet ID to be written as string, so it doesnt truncate as scientific notation\n",
    "    lista_valores_atuais[1] = '\\''+lista_valores_atuais[1]\n",
    "\n",
    "    logging('LISTA_VALORES_ATUAIS: '+str(lista_valores_atuais))\n",
    "\n",
    "    # se arquivo do dia já existe, vai dar append apenas no conteúdo daquele tweet, caso contrário, \n",
    "    # vai criar o arquivo e vai dar append\n",
    "    # no header e depois no tweet \n",
    "\n",
    "    if not os.path.exists(CSV_path):\n",
    "        logging('today s csv does not exist yet, creating it and appending header')\n",
    "        header_csv = ['created_at','tweet_ID','user','tweet_content','place','language','source'] \n",
    "        with open(CSV_path, \"a\") as file:\n",
    "            wr = csv.writer(file)\n",
    "            wr.writerow(header_csv)\n",
    "            \n",
    "    with open(CSV_path, \"a\",encoding=\"utf-8\", newline='') as file:\n",
    "        logging('writing lista_valores_atuais anyways')\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow(lista_valores_atuais)\n",
    "\n",
    "    # df = pd.DataFrame(lista_valores_atuais) # turning into data frame\n",
    "    # df.to_csv(path_or_buf = CSV_path, mode='a',index=False, cols = header_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(text_to_log=\"\"):\n",
    "    \n",
    "    # converte parâmetro que ele quer escrever no log em string, caso tenha sido enviado em outro formato\n",
    "    text_to_log = str(text_to_log)\n",
    "    \n",
    "    # prepara data e timestamp pra dar append no arquivo de log (ou escrever um novo) + timestamp no conteúdo do arquivo\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\")\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "    \n",
    "    # busca diretório onde o robô está rodando e formata o path pro log do dia corrente\n",
    "    current_directory = os.getcwd()  \n",
    "    log_path = current_directory+'\\\\arquivos_bot\\\\logs\\\\log_'+date+'.txt'\n",
    "\n",
    "    # se arquivo do dia já existir, só escreve nele o timestamp + conteúdo do parámetro\n",
    "    # caso contrário, cria o arquivo de log daquele dia \n",
    "    with open(log_path, 'a+',encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(timestamp+ ' - ' + text_to_log+'\\n')\n",
    "    \n",
    "    # além de escrever no arquivo, printa no jupyter\n",
    "    print(timestamp+ ' - ' + text_to_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_special_text_to_ascii(original_text):\n",
    "    translated_text = ''\n",
    "\n",
    "    for character in original_text:\n",
    "        if ord(character) >= 128:\n",
    "            translated_text = translated_text + '\"Chr(' + str(ord(character)) + ')\"'\n",
    "        else:\n",
    "            translated_text = translated_text + character\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    # ---------------------  CRIA PASTAS QUE O ROBÔ VAI USAR NO DIRETÓRIO DO SCRIPT  ---------------------------\n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    # ------------------------- e json de controle também, caso nada disso exista ------------------------------\n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    current_directory = os.getcwd()\n",
    "    if not os.path.exists(current_directory+'\\\\arquivos_bot\\\\logs'):\n",
    "        pymsgbox.alert(text='Criando pasta de logs', title='Preparando bot', button='OK',timeout=4500)\n",
    "        os.makedirs(current_directory+'\\\\arquivos_bot\\\\logs')\n",
    "        logging(\"Preparando ambiente\")\n",
    "        logging(\"Criando pasta de logs\")\n",
    "    \n",
    "    if not os.path.exists(current_directory+'\\\\arquivos_bot\\\\controle'):\n",
    "        pymsgbox.alert(text='Criando pasta de controle', title='Preparando bot', button='OK',timeout=4500)\n",
    "        os.makedirs(current_directory+'\\\\arquivos_bot\\\\controle')\n",
    "        logging(\"Criando pasta de controle\")\n",
    "\n",
    "    if not os.path.exists(current_directory+'\\\\arquivos_bot\\\\dados_exportados'):\n",
    "        pymsgbox.alert(text='Criando pasta de dados exportados', title='Preparando bot', button='OK',timeout=4500)\n",
    "        os.makedirs(current_directory+'\\\\arquivos_bot\\\\dados_exportados')\n",
    "        logging(\"Criando pasta de dados exportados\")\n",
    "    \n",
    "    \n",
    "    # checking if control json exists, otherwise we create it\n",
    "    if not os.path.exists(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json'):\n",
    "        logging(\"arquivo json não encontrado\")\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"%d/%m/%Y\")\n",
    "        write_json_and_updates_value(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False,inicializar = True)\n",
    "    \n",
    "    # checking if credentials json exists, otherwise we create it\n",
    "    \n",
    "    with open(current_directory+'\\\\arquivos_bot\\\\credentials.json') as credentials_file:\n",
    "        credential = json.load(credentials_file)\n",
    "        #supposed to be a dictionary \n",
    "        logging('tipo da variavel credential: '+str(type(credential)))\n",
    "        logging('valor credential:  '+ str(credential))\n",
    "                             \n",
    "    pymsgbox.alert('Pastas necessárias para o robô conferidas, iniciando o bot', 'Starting bot',timeout=5000)\n",
    "    logging(\"░██████╗████████╗░█████╗░██████╗░████████╗██╗███╗░░██╗░██████╗░\")\n",
    "    logging(\"██╔════╝╚══██╔══╝██╔══██╗██╔══██╗╚══██╔══╝██║████╗░██║██╔════╝░\")\n",
    "    logging(\"╚█████╗░░░░██║░░░███████║██████╔╝░░░██║░░░██║██╔██╗██║██║░░██╗░\")\n",
    "    logging(\"░╚═══██╗░░░██║░░░██╔══██║██╔══██╗░░░██║░░░██║██║╚████║██║░░╚██╗\")\n",
    "    logging(\"██████╔╝░░░██║░░░██║░░██║██║░░██║░░░██║░░░██║██║░╚███║╚██████╔╝\")\n",
    "    logging(\"╚═════╝░░░░╚═╝░░░╚═╝░░╚═╝╚═╝░░╚═╝░░░╚═╝░░░╚═╝╚═╝░░╚══╝░╚═════╝░\")\n",
    "    \n",
    "    credential =  {\n",
    "                    \"api_key\" : credentials.API_KEY,\n",
    "                    \"api_secret\" : credentials.API_SECRET,\n",
    "                    \"bearer_token\" : credentials.BEARER_TOKEN,\n",
    "                    \"access_token\" : credentials.ACCESS_TOKEN,\n",
    "                    \"access_token_secret\" : credentials.ACCESS_TOKEN_SECRET\n",
    "                    }\n",
    "    \n",
    "    api = authenticating(credential)\n",
    "\n",
    "    words = ['zolpidem','ambien']\n",
    "    \n",
    "    for searched_word in words:\n",
    "        \n",
    "        for tweet in tweepy.Cursor(api.search, q = searched_word ).items(1100):\n",
    "            \n",
    "            dict_tweets_info = {\n",
    "            \"created_at\": [],\n",
    "            \"tweet_ID\": [],\n",
    "            \"user\": [],\n",
    "            \"tweet_content\": [],\n",
    "            \"place\": [],\n",
    "            \"language\": [],\n",
    "            \"source\": [] \n",
    "        }\n",
    "\n",
    "            with open(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json') as json_file:\n",
    "                tweets_status = json.load(json_file)\n",
    "                if tweets_status[\"amount_of_tweets\"] == 999 and tweets_status['current_date'] == date:\n",
    "                    sys.exit('DAILY LIMIT REACHED, CANT RETWEET MORE THAN 1000 TWEETS')\n",
    "\n",
    "            valid_tweet = print_and_retweet_tweet(api,tweet,dict_tweets_info,searched_word)\n",
    "\n",
    "            if isinstance(valid_tweet,dict):\n",
    "                logging('VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now')\n",
    "                export_infos_to_csv(valid_tweet)\n",
    "                write_json_and_updates_value(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False)\n",
    "                \n",
    "            elif isinstance(valid_tweet,int):\n",
    "                logging('Tweet is not valid, analyzing return:: '+str(valid_tweet))\n",
    "                cases={\n",
    "                    -1:\"didn't found the searched_word on tweet.text it self \",\n",
    "                    -2:\"japanese or korean language\",\n",
    "                    -3:'you have already retweeted this Tweet',\n",
    "                    -4:'RateLimitError',\n",
    "                    -5:'you are the owner of this tweet',\n",
    "                    -6:\"tweet was made by the bot's account, we can't retweet stuff made by us\"\n",
    "                }\n",
    "                logging(cases.get(valid_tweet,\"Invalid return\"))\n",
    "                write_json_and_updates_value(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=True)\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                logging('Unexpected return for print_and_retweet_tweet different than dict or int!! content: '+str(valid_tweet))\n",
    "                write_json_and_updates_value(current_directory+'\\\\arquivos_bot\\\\controle\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False)\n",
    "            \n",
    "            logging(\"Waiting 2 min for retrieve another tweet cuz we like safety\")\n",
    "            time.sleep(60*2) # sleep 2 min, so we dont reach the limit 100 tweets per hour\n",
    "        \n",
    "    \n",
    "    logging('███████╗███╗░░██╗██████╗░  ░█████╗░███████╗  ██╗░░░░░░█████╗░██████╗░')\n",
    "    logging('██╔════╝████╗░██║██╔══██╗  ██╔══██╗██╔════╝  ██║░░░░░██╔══██╗██╔══██╗')\n",
    "    logging('█████╗░░██╔██╗██║██║░░██║  ██║░░██║█████╗░░  ██║░░░░░███████║██████╔╝')\n",
    "    logging('██╔══╝░░██║╚████║██║░░██║  ██║░░██║██╔══╝░░  ██║░░░░░██╔══██║██╔═══╝░')\n",
    "    logging('███████╗██║░╚███║██████╔╝  ╚█████╔╝██║░░░░░  ███████╗██║░░██║██║░░░░░')\n",
    "    logging('╚══════╝╚═╝░░╚══╝╚═════╝░  ░╚════╝░╚═╝░░░░░  ╚══════╝╚═╝░░╚═╝╚═╝░░░░░')\n",
    "    \n",
    "    pymsgbox.alert('$$$$$$$$$$$$$$ \\n FIM DA LAP\\n $$$$$$$$$$$$$', 'End of times',timeout=40000)\n",
    "\n",
    "    \n",
    "    \n",
    "    # bot by: @minhadona, jan.2021\n",
    "    # big letters font generator: https://fsymbols.com/generators/tarty/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/01/2021, 19:13:51 - tipo da variavel credential: <class 'dict'>\n",
      "11/01/2021, 19:13:51 - valor credential:  {'api_key': 'n9mO2yvbdJPYx8TbR2f1eDD6e', 'api_secret': 'fa1iOHkiroO8g92xcMkCFb3Tbb2FzPlr4K8v7J0B71GA2yueuv', 'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAH5lLAEAAAAADTVzg%2FPB5pzCLIdSnykChu6ILb4%3D8dqi1ZN8TOQP4cKRyhIOmUu3DLwRlHlRQm0Z9oe6E9JFY1vl9l', 'access_token': '1337178878364819457-USWqazl9efISYFcxDwPNdldEzW0lY6', 'access_token_secret': 'ct42tmOxwbmHBVxYbj7xm2iA2ItkqgC91RLG6Uk9bddY7'}\n",
      "11/01/2021, 19:13:56 - ░██████╗████████╗░█████╗░██████╗░████████╗██╗███╗░░██╗░██████╗░\n",
      "11/01/2021, 19:13:56 - ██╔════╝╚══██╔══╝██╔══██╗██╔══██╗╚══██╔══╝██║████╗░██║██╔════╝░\n",
      "11/01/2021, 19:13:57 - ╚█████╗░░░░██║░░░███████║██████╔╝░░░██║░░░██║██╔██╗██║██║░░██╗░\n",
      "11/01/2021, 19:13:57 - ░╚═══██╗░░░██║░░░██╔══██║██╔══██╗░░░██║░░░██║██║╚████║██║░░╚██╗\n",
      "11/01/2021, 19:13:57 - ██████╔╝░░░██║░░░██║░░██║██║░░██║░░░██║░░░██║██║░╚███║╚██████╔╝\n",
      "11/01/2021, 19:13:57 - ╚═════╝░░░░╚═╝░░░╚═╝░░╚═╝╚═╝░░╚═╝░░░╚═╝░░░╚═╝╚═╝░░╚══╝░╚═════╝░\n",
      "11/01/2021, 19:13:57 - \n",
      "\n",
      "function>>>>>authenticating\n",
      "<class 'tweepy.api.API'>\n",
      "11/01/2021, 19:13:57 - \n",
      "\n",
      "function>>>>>print_and_retweet_tweet\n",
      "11/01/2021, 19:13:57 - appending infos to dictionary\n",
      "11/01/2021, 19:13:57 - ----------------------------------------\n",
      "11/01/2021, 19:13:57 - collected informations\n",
      "11/01/2021, 19:13:57 - ----------------------------------------\n",
      "11/01/2021, 19:13:57 - dict_tweets_info: \n",
      " {'created_at': ['2021-01-11 22:09:49'], 'tweet_ID': ['1348754008882753536'], 'user': ['zolpidembot'], 'tweet_content': ['RT @blancavocados: @Lauramg21 Zolpidem (hipnótico)'], 'place': ['None'], 'language': ['es'], 'source': ['None']}\n",
      "11/01/2021, 19:13:57 - ----------------------------------------\n",
      "11/01/2021, 19:13:57 - print_and_retweet_tweet(): better filtering BEFORE retweet\n",
      "11/01/2021, 19:13:57 - teoricamente nao esta em japones nem coreano, está em: es\n",
      "11/01/2021, 19:13:58 - this tweet was made by yourself using your bot profile or is an old RETWEET !!we wont retweet it again\n",
      "11/01/2021, 19:13:58 - Tweet is not valid, analyzing return:: -6\n",
      "11/01/2021, 19:13:58 - tweet was made by the bot's account, we can't retweet stuff made by us\n",
      "11/01/2021, 19:13:58 - \n",
      "\n",
      "function>>>>>write_json_and_updates_value\n",
      "11/01/2021, 19:13:58 - same date!! so, just change the value of tweetts\n",
      "11/01/2021, 19:13:58 - INCREMENTANDO CHAVE DE CONTAGEM TOTAL DE TWEETS\n",
      "11/01/2021, 19:13:58 - \n",
      "\n",
      "function>>>>>print_and_retweet_tweet\n",
      "11/01/2021, 19:13:58 - appending infos to dictionary\n",
      "11/01/2021, 19:13:58 - ----------------------------------------\n",
      "11/01/2021, 19:13:58 - collected informations\n",
      "11/01/2021, 19:13:58 - ----------------------------------------\n",
      "11/01/2021, 19:13:58 - dict_tweets_info: \n",
      " {'created_at': ['2021-01-11 22:08:07'], 'tweet_ID': ['1348753582229741580'], 'user': ['obrunopaiva'], 'tweet_content': ['Hoje o soninho vai ser na base do zolpidem.............'], 'place': ['None'], 'language': ['pt'], 'source': ['https://mobile.twitter.com']}\n",
      "11/01/2021, 19:13:58 - ----------------------------------------\n",
      "11/01/2021, 19:13:58 - print_and_retweet_tweet(): better filtering BEFORE retweet\n",
      "11/01/2021, 19:13:58 - teoricamente nao esta em japones nem coreano, está em: pt\n",
      "11/01/2021, 19:13:58 - this user is not you! you: zolpidembot VS the tweeter: obrunopaiva, that s great\n",
      "11/01/2021, 19:13:58 - retweeting ←←←←←←←←←←←←←\n",
      "11/01/2021, 19:13:58 - →→→→→→→→→→→→→ retweeted\n",
      "11/01/2021, 19:13:58 - VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now\n",
      "11/01/2021, 19:13:58 - \n",
      "\n",
      "function>>>>>exporting_infos_to_csv\n",
      "11/01/2021, 19:13:58 - log path: C:\\Users\\gabri\\Documents\\retweet-bot\\arquivos_bot\\dados_exportados\\dados_11-01-2021.csv\n",
      "11/01/2021, 19:13:58 - dict_tweets_info : {'created_at': ['2021-01-11 22:08:07'], 'tweet_ID': ['1348753582229741580'], 'user': ['obrunopaiva'], 'tweet_content': ['Hoje o soninho vai ser na base do zolpidem.............'], 'place': ['None'], 'language': ['pt'], 'source': ['https://mobile.twitter.com']}\n",
      "11/01/2021, 19:13:58 - LISTA_VALORES_ATUAIS: ['2021-01-11 22:08:07', \"'1348753582229741580\", 'obrunopaiva', 'Hoje o soninho vai ser na base do zolpidem.............', 'None', 'pt', 'https://mobile.twitter.com']\n",
      "11/01/2021, 19:13:58 - writing lista_valores_atuais anyways\n",
      "11/01/2021, 19:13:58 - \n",
      "\n",
      "function>>>>>write_json_and_updates_value\n",
      "11/01/2021, 19:13:58 - same date!! so, just change the value of tweetts\n",
      "11/01/2021, 19:13:58 - increases both keys , the including failure and the sucessed amounts\n",
      "11/01/2021, 19:13:58 - Waiting 2 min for retrieve another tweet cuz we like safety\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import credentials\n",
    "import tweepy\n",
    "import time\n",
    "from datetime import date, datetime \n",
    "import os\n",
    "import pymsgbox \n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
