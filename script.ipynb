{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticating(credential):\n",
    "    logging('\\n\\nfunction>>>>>authenticating')\n",
    "     \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # credential         • <dictionary>                 ○ its keys will be used to authenticate\n",
    "        \n",
    "    \"\"\"\n",
    "    █▀█ █░█ ▀█▀\n",
    "    █▄█ █▄█ ░█░\n",
    "    \"\"\"\n",
    "        # api                • <class 'tweepy.api.API'>     ○ authenticated api\n",
    "   \n",
    "    auth = tweepy.OAuthHandler(credential[\"api_key\"], credential[\"api_secret\"])\n",
    "    auth.set_access_token(credential[\"access_token\"], credential[\"access_token_secret\"])\n",
    "\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_retweet_tweet(api, tweet, dict_tweets_info, searched_word):\n",
    "    logging('\\n\\nfunction>>>>>validate_and_retweet_tweet')\n",
    "    \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # api                • <class 'tweepy.api.API'>    ○ authenticated api\n",
    "        # tweet              • <tweet object>              ○ one single tweet object and its attributes \n",
    "        # dict_tweets_info   • <dictionary>                ○ empty, to be filled with informations from this tweet object\n",
    "        # searched_word      • <string>                    ○ seeking term (will be used here to validate the inner content of the tweet) \n",
    "    \n",
    "    \"\"\"\n",
    "    █▀█ █░█ ▀█▀\n",
    "    █▄█ █▄█ ░█░\n",
    "    \"\"\"\n",
    "        # -1           ○ didn't found the searched_word on tweet.text it self \n",
    "        # -2           ○ invalid language (japanese, korean, arabic etc problems to recognize the searched word)\n",
    "        # -3           ○ you have already retweeted this Tweet\n",
    "        # -4           ○ RateLimitError\n",
    "        # -5           ○ tweet was made by the bot's account, we can't retweet stuff made by us \n",
    "        # dict         ○ in a valid situation, returns a populated dictionary containing this tweet's data \n",
    "\n",
    "    try: \n",
    "\n",
    "        logging('appending infos retrieved to dictionary')\n",
    "        dict_tweets_info['created_at'].append(str(tweet.created_at))\n",
    "        dict_tweets_info['tweet_ID'].append(str(tweet.id))\n",
    "        dict_tweets_info['user'].append(str(tweet.user.screen_name))\n",
    "        dict_tweets_info['tweet_content'].append((tweet.text))\n",
    "        dict_tweets_info['place'].append(str(tweet.place))\n",
    "        dict_tweets_info['language'].append(str(tweet.lang))\n",
    "        dict_tweets_info['source'].append(str(tweet.source_url).replace(\"http://twitter.com/download/\",\"\"))\n",
    "    \n",
    "        logging('----------------------------------------')\n",
    "        logging('raw dict_tweets_info after appending: \\n '+str(dict_tweets_info))\n",
    "        logging('----------------------------------------')\n",
    "        \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------- FILTERING BEFORE RETWEET ----------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        logging('validate_and_retweet_tweet(): better filtering BEFORE retweet')\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if it's in a translatable language ----------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        string_lang_content = \"\".join(dict_tweets_info['language'] )  # turns list into string to compare\n",
    "        if string_lang_content in ['ja','ko','und','fa','ar']:\n",
    "            logging('dumb robot, tweet is not in an understandable language so its content will be wrongly evaluated, we stop here')\n",
    "            return -2\n",
    "        else: \n",
    "            logging('not in any forbidden language! language is actually:'+string_lang_content)\n",
    "            \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if the searched word really is on tweet content ---------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "        string_tweet_content = \"\".join(dict_tweets_info['tweet_content'] ) # turns list into string to compare\n",
    "        if not searched_word in string_tweet_content.lower():\n",
    "            logging('we havent found '+ searched_word + ' on tweet content')\n",
    "            # NO WAY it's gonna retweet something that has NOT the word on the text\n",
    "            return -1\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------------------------- checking if this tweet's user is also the authenticated user --------------\n",
    "        # -------------------------------- (so we dont retweet our own tweets) --------------------------------\n",
    "        \n",
    "        my_user_object = api.me()\n",
    "        if str(my_user_object.screen_name) == str(tweet.user.screen_name):\n",
    "            logging('you are @'+ str(my_user_object.screen_name))\n",
    "            logging('this tweet was made by yourself using your bot profile or is an old RETWEET!! both cases we wont retweet it again')\n",
    "            return -5\n",
    "        else:\n",
    "            logging('this user is not you! you: '+ str(my_user_object.screen_name) + ' VS the tweeter: '+ str(tweet.user.screen_name) +', that s great')\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # ---------------------------------- RETWEET ACTION ! -----------------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "        logging('retweeting ←←←←←←←←←←←←←')\n",
    "        api.retweet(tweet.id)\n",
    "        logging('→→→→→→→→→→→→→ retweeted') # if an exception is raised during retweet method, we wont arrive here\n",
    "        return dict_tweets_info\n",
    "    \n",
    "    except tweepy.TweepError as e: \n",
    "        if e.api_code == 327:\n",
    "            logging('Exception Code 327: You have already retweeted this Tweet')\n",
    "            return -3\n",
    "        \n",
    "    except tweepy.RateLimitError as e:\n",
    "        logging('RateLimitError')\n",
    "        logging('Unknown error: '+str(e))\n",
    "        logging('according to internet, sleeping for 15 min should solve...')\n",
    "        time.sleep(60 * 15)  # we saw rate limit is ignored after 15 min ??? ///not confirmed hypothesis///\n",
    "        return -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_and_updates_value(path, incrementa_contagem_de_falha=False, inicializar = False):\n",
    "    logging('\\n\\nfunction>>>>>write_json_and_updates_value')\n",
    "    \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # path                           • <string>          ○ control json path\n",
    "        # incrementa_contagem_de_falha   • <bool>            ○ boolean flag to update or not a specific key\n",
    "        # inicializar                    • <bool>            ○ boolean flag to reset (set to 0) or not all the keys\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_date = now.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # try to read from file\n",
    "    try:\n",
    "        with open(path) as json_file:\n",
    "            tweets_status = json.load(json_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    # write on file\n",
    "    # if our current date is the same, increase amount of tweets.\n",
    "    # if our current date is different, amount is ZERO !!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    if inicializar or tweets_status['current_date'] != current_date: \n",
    "        logging('different dates, OR initializing, so we need to change the current_date value and also turn into 0 all the values')\n",
    "        with open(path, 'w') as f:\n",
    "            try:\n",
    "                content = {\"current_date\": current_date,\n",
    "                           \"amount_of_tweets\": 0,\n",
    "                           \"total_amount_including_failure\":0}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "    else: \n",
    "        logging('same date!! so, just change the value of tweetts')\n",
    "        if not incrementa_contagem_de_falha:\n",
    "                logging('increases both keys , the including failure and the sucessed amounts')\n",
    "                #vai incrementtar o total com falhas tb + o total dos sucessos\n",
    "                tweets_status[\"amount_of_tweets\"] = tweets_status[\"amount_of_tweets\"]+1 \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)\n",
    "                    \n",
    "        elif incrementa_contagem_de_falha:\n",
    "                # vai incrementar SOMENTE chave com total de tweets, independente de ter falhado ou nao\n",
    "                logging('INCREMENTANDO CHAVE DE CONTAGEM TOTAL DE TWEETS')\n",
    "                     # increasing amount of the ones who failure \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_infos_to_csv(valid_tweet):\n",
    "    logging('\\n\\nfunction>>>>>exporting_infos_to_csv')\n",
    "        \n",
    "    \"\"\"   \n",
    "    █ █▄░█\n",
    "    █ █░▀█    \n",
    "    \"\"\"\n",
    "        # valid tweet        • <dictionary>          ○ dictionary holding all informations we retrieved from one specific tweet\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # ------------------------- fetch today's DATE in DD/MM/YYY format and turns into DD-MM-YYYY ------------------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_directory = os.getcwd()  \n",
    "    timestamp = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\").replace(':',\"-\").replace(',','--').replace(\" \",\"\")\n",
    "\n",
    "    CSV_path = current_directory+'\\\\bot_files\\\\exported_data\\\\dados_'+timestamp+'.csv'\n",
    "    logging(\"today's CSV path: \"+str(CSV_path))\n",
    "\n",
    "    logging('valid_tweet : '+str(valid_tweet))\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # -------- to exclusively append tweet's informations, we CANT append dict directly, otherwise the function ---\n",
    "    # ------------- will append header (dict keys) row + informations (dict values) row for EVERY tweet -----------\n",
    "    # --------- so we turn the dict values into a list and we only append header if it's a new CSV (new day) ------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------- turning dict values into a list ----------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version = []\n",
    "    for key, value in valid_tweet.items():\n",
    "        dict_values_in_list_version.append(\"\".join(value))\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # -------- forcing Tweet ID to be written as string on sheet, so it doesnt truncate as scientific notation --\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version[1] = '\\''+dict_values_in_list_version[1]\n",
    "\n",
    "    logging('dict_values_in_list_version: '+str(dict_values_in_list_version))\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # --------- if today's CSV already exists, we will append only this specific tweet's DETAILS to file --------\n",
    "        # ----------------- elseways we append the header (creating a new file) -------------------------------------\n",
    "        # ------------------- and THEN append current tweet's details normally --------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    if not os.path.exists(CSV_path):\n",
    "        logging('today s csv does not exist yet, creating it and appending header')\n",
    "        header_csv = ['created_at','tweet_ID','user','tweet_content','place','language','source'] \n",
    "        with open(CSV_path, \"a\") as file:\n",
    "            wr = csv.writer(file)\n",
    "            wr.writerow(header_csv)\n",
    "            \n",
    "    with open(CSV_path, \"a\",encoding=\"utf-8\", newline='') as file:\n",
    "        logging('writing tweet details on CSV file')\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow(dict_values_in_list_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(text_to_log=\"\"):\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # ------------------- converts into string the parameter we want to write on log file -----------------------\n",
    "    # ------------------------- just in case we received another variable type ----------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    text_to_log = str(text_to_log)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------- fetchs timestamp to append within received text -------------------------------\n",
    "    # ---------- fetchs current date to create new log file or append to the current one ------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\")\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---- retrieves directory where our robot is running and concatenate the path to the current day's ---\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    current_directory = os.getcwd()  \n",
    "    log_path = current_directory+'\\\\bot_files\\\\logs\\\\log_'+date+'.txt'\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ----- appending to file of the day: timestamp + parameter's content ---------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    with open(log_path, 'a+',encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(timestamp+ ' - ' + text_to_log+'\\n')\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------ printing on console ----------------------------------------------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    print(timestamp+ ' - ' + text_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_special_text_to_ascii(original_text):\n",
    "    translated_text = ''\n",
    "\n",
    "    for character in original_text:\n",
    "        if ord(character) >= 128:\n",
    "            translated_text = translated_text + '\"Chr(' + str(ord(character)) + ')\"'\n",
    "        else:\n",
    "            translated_text = translated_text + character\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    current_directory = os.getcwd()\n",
    "    checks_if_necessary_folders_exist_otherwise_create_them(current_directory)\n",
    "    checks_if_necessary_files_exist_otherwise_create_them(current_directory)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ---------------------- populating dictionary with API credentials ----------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    \n",
    "    with open(current_directory+'\\\\bot_files\\\\controls\\\\credentials.json') as credentials_file:\n",
    "        credentials = json.load(credentials_file)\n",
    "        logging('credential value: '+ str(credentials))\n",
    "                             \n",
    "    pymsgbox.alert('Starting bot!', 'Starting bot',timeout=5000)\n",
    "    logging(\"░██████╗████████╗░█████╗░██████╗░████████╗██╗███╗░░██╗░██████╗░\")\n",
    "    logging(\"██╔════╝╚══██╔══╝██╔══██╗██╔══██╗╚══██╔══╝██║████╗░██║██╔════╝░\")\n",
    "    logging(\"╚█████╗░░░░██║░░░███████║██████╔╝░░░██║░░░██║██╔██╗██║██║░░██╗░\")\n",
    "    logging(\"░╚═══██╗░░░██║░░░██╔══██║██╔══██╗░░░██║░░░██║██║╚████║██║░░╚██╗\")\n",
    "    logging(\"██████╔╝░░░██║░░░██║░░██║██║░░██║░░░██║░░░██║██║░╚███║╚██████╔╝\")\n",
    "    logging(\"╚═════╝░░░░╚═╝░░░╚═╝░░╚═╝╚═╝░░╚═╝░░░╚═╝░░░╚═╝╚═╝░░╚══╝░╚═════╝░\")\n",
    "    \n",
    "    try: \n",
    "        api = authenticating(credentials)\n",
    "\n",
    "        words = ['zolpidem','ambien']\n",
    "\n",
    "        for searched_word in words:\n",
    "\n",
    "            for tweet in tweepy.Cursor(api.search, q = searched_word).items(1100):\n",
    "\n",
    "                dict_tweets_info = {\n",
    "                \"created_at\": [],\n",
    "                \"tweet_ID\": [],\n",
    "                \"user\": [],\n",
    "                \"tweet_content\": [],\n",
    "                \"place\": [],\n",
    "                \"language\": [],\n",
    "                \"source\": [] \n",
    "            }\n",
    "\n",
    "                with open(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json') as json_file:\n",
    "                    tweets_status = json.load( json_file)\n",
    "                    if tweets_status[\"amount_of_tweets\"] == 999 and tweets_status['current_date'] == date:\n",
    "                        sys.exit('DAILY LIMIT REACHED, CANT RETWEET MORE THAN 1000 TWEETS')\n",
    "\n",
    "                valid_tweet = validate_and_retweet_tweet(api,\n",
    "                                                         tweet,\n",
    "                                                         dict_tweets_info,\n",
    "                                                         searched_word)\n",
    "\n",
    "                if isinstance(valid_tweet,type(dict)):\n",
    "                    logging('VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now')\n",
    "                    export_infos_to_csv(valid_tweet)\n",
    "                    write_json_and_updates_value(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False)\n",
    "\n",
    "                elif isinstance(valid_tweet,int):\n",
    "                    logging('Tweet is not valid, analyzing return:: '+str(valid_tweet))\n",
    "                    cases={\n",
    "                        -1 : \"didn't found the searched_word on tweet.text it self\",\n",
    "                        -2 : \"invalid language (japanese, korean, arabic etc problems to recognize the searched word)\",\n",
    "                        -3 : \"you have already retweeted this Tweet\",\n",
    "                        -4 : \"RateLimitError\",\n",
    "                        -5 : \"tweet was made by the bot's account, we can't retweet stuff made by us\"\n",
    "                    }\n",
    "                    logging(cases.get(valid_tweet,\"Invalid return\"))\n",
    "                    write_json_and_updates_value(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=True)\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    logging('Unexpected return for validate_and_retweet_tweet different than dict or int!! content: '+str(valid_tweet))\n",
    "                    write_json_and_updates_value(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False)\n",
    "\n",
    "                logging(\"Waiting 2 min for retrieve another tweet cuz we like safety\")\n",
    "                time.sleep(60*2) # sleep 2 min, so we dont reach the limit 100 tweets per hour\n",
    "    \n",
    "    except Exception as error:\n",
    "        if 'status code = 401' in str(error):\n",
    "            logging('INVALID CREDENTIALS, STOPPING BOT')\n",
    "            pymsgbox.alert('INVALID CREDENTIALS on jsoOoooOOooOon!!!\\nPLEASE UPDATE YOUR CREDENTIALS ON \\\\bot_files\\\\controls\\\\credentials.json', 'Stopping bot',timeout=15000)\n",
    "            sys.exit('stopping program')\n",
    "\n",
    "    logging('███████╗███╗░░██╗██████╗░  ░█████╗░███████╗  ██╗░░░░░░█████╗░██████╗░')\n",
    "    logging('██╔════╝████╗░██║██╔══██╗  ██╔══██╗██╔════╝  ██║░░░░░██╔══██╗██╔══██╗')\n",
    "    logging('█████╗░░██╔██╗██║██║░░██║  ██║░░██║█████╗░░  ██║░░░░░███████║██████╔╝')\n",
    "    logging('██╔══╝░░██║╚████║██║░░██║  ██║░░██║██╔══╝░░  ██║░░░░░██╔══██║██╔═══╝░')\n",
    "    logging('███████╗██║░╚███║██████╔╝  ╚█████╔╝██║░░░░░  ███████╗██║░░██║██║░░░░░')\n",
    "    logging('╚══════╝╚═╝░░╚══╝╚═════╝░  ░╚════╝░╚═╝░░░░░  ╚══════╝╚═╝░░╚═╝╚═╝░░░░░')\n",
    "    \n",
    "    pymsgbox.alert('$$$$$$$$$$$$$$ \\n END OF LAP\\n $$$$$$$$$$$$$', 'End of times',timeout=40000)\n",
    "\n",
    "    # bot by: @minhadona, jan.2021\n",
    "    # big letters font generator: https://fsymbols.com/generators/tarty/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_files_exist_otherwise_create_them(current_directory):\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # ---------- checking if control json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "\n",
    "    if not os.path.exists(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json'):\n",
    "        logging(\"control json not found, gotta create it\")\n",
    "        write_json_and_updates_value(current_directory+'\\\\bot_files\\\\controls\\\\amount_of_tweets_from_today.json',incrementa_contagem_de_falha=False,inicializar = True)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------    \n",
    "    # ---------- checking if credentials json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "    credentials_path = current_directory+'\\\\bot_files\\\\controls\\\\credentials.json'\n",
    "    if not os.path.exists(credentials_path):\n",
    "        logging(\"credentials json not found, gotta create it using a template\")\n",
    "        \n",
    "        with open(credentials_path, 'w') as f:\n",
    "            try:\n",
    "                content = {\"api_key\" : \"examplen9masss23423553252ffffffe\",\n",
    "                           \"api_secret\" : \"examplefa1asfsafsafsa32434fdfsfsdfddsfsfddfdfsfd\",\n",
    "                           \"bearer_token\" : \"exampleAAAAAAAAAADFDSFGDDGGDAGDFHDFHBV424G4023fe032402320F242WER355W31tg21e454F4E4ER4Esfdsdfdfs\",\n",
    "                           \"access_token\" : \"example13371788gfdfgdfgdfgd344544gdfgfdsj5jytjjy\",\n",
    "                           \"access_token_secret\" : \"examplect42gdfhf5y66hsvbbgfhC91Rhfghgf45t4555552432324235\"}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_folders_exist_otherwise_create_them(current_directory):\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # ---------------------  CREATES INTO SCRIPT DIRECTORY ALL NECESSARY FOLDERS  ------------------\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    logging('current directory is supposed to be: '+str(current_directory))\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(current_directory+'\\\\bot_files\\\\logs'):\n",
    "            pymsgbox.alert(text=\"Creating logs' folder\", title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(current_directory+'\\\\bot_files\\\\logs')\n",
    "            logging(\"Creating logs' folder\")\n",
    "\n",
    "        if not os.path.exists(current_directory+'\\\\bot_files\\\\controls'):\n",
    "            pymsgbox.alert(text='Creating controls folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(current_directory+'\\\\bot_files\\\\controls')\n",
    "            logging(\"Creating controls folder\")\n",
    "\n",
    "        if not os.path.exists(current_directory+'\\\\bot_files\\\\exported_data'):\n",
    "            pymsgbox.alert(text='Creating exported_data folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(current_directory+'\\\\bot_files\\\\exported_data')\n",
    "            logging(\"Creating exported_data folder\")\n",
    "    \n",
    "    except Exception as error:\n",
    "        logging('Unknown error: '+str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/01/2021, 22:56:34 - current directory is supposed to be: C:\\Users\\gabri\\Documents\\retweet-bot\n",
      "12/01/2021, 22:56:34 - credential value: {'api_key': 'n9mO2yvbdJPYx8TbR2f1eDD6e', 'api_secret': 'fa1iOHkiroO8g92xcMkCFb3Tbb2FzPlr4K8v7J0B71GA2yueuv', 'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAH5lLAEAAAAADTVzg%2FPB5pzCLIdSnykChu6ILb4%3D8dqi1ZN8TOQP4cKRyhIOmUu3DLwRlHlRQm0Z9oe6E9JFY1vl9l', 'access_token': '1337178878364819457-USWqazl9efISYFcxDwPNdldEzW0lY6', 'access_token_secret': 'ct42tmOxwbmHBVxYbj7xm2iA2ItkqgC91RLG6Uk9bddY7'}\n",
      "12/01/2021, 22:56:34 - ░██████╗████████╗░█████╗░██████╗░████████╗██╗███╗░░██╗░██████╗░\n",
      "12/01/2021, 22:56:34 - ██╔════╝╚══██╔══╝██╔══██╗██╔══██╗╚══██╔══╝██║████╗░██║██╔════╝░\n",
      "12/01/2021, 22:56:34 - ╚█████╗░░░░██║░░░███████║██████╔╝░░░██║░░░██║██╔██╗██║██║░░██╗░\n",
      "12/01/2021, 22:56:34 - ░╚═══██╗░░░██║░░░██╔══██║██╔══██╗░░░██║░░░██║██║╚████║██║░░╚██╗\n",
      "12/01/2021, 22:56:34 - ██████╔╝░░░██║░░░██║░░██║██║░░██║░░░██║░░░██║██║░╚███║╚██████╔╝\n",
      "12/01/2021, 22:56:34 - ╚═════╝░░░░╚═╝░░░╚═╝░░╚═╝╚═╝░░╚═╝░░░╚═╝░░░╚═╝╚═╝░░╚══╝░╚═════╝░\n",
      "12/01/2021, 22:56:34 - \n",
      "\n",
      "function>>>>>authenticating\n",
      "12/01/2021, 22:56:35 - \n",
      "\n",
      "function>>>>>validate_and_retweet_tweet\n",
      "12/01/2021, 22:56:35 - appending infos retrieved to dictionary\n",
      "12/01/2021, 22:56:35 - ----------------------------------------\n",
      "12/01/2021, 22:56:35 - raw dict_tweets_info after appending: \n",
      " {'created_at': ['2021-01-13 01:54:23'], 'tweet_ID': ['1349172914650816514'], 'user': ['itsmecapituu'], 'tweet_content': ['Será que tomar dois zolpidem, alprazolam e 200mg de sertralina da ruim?'], 'place': ['None'], 'language': ['pt'], 'source': ['iphone']}\n",
      "12/01/2021, 22:56:35 - ----------------------------------------\n",
      "12/01/2021, 22:56:35 - validate_and_retweet_tweet(): better filtering BEFORE retweet\n",
      "12/01/2021, 22:56:35 - not in any forbidden language! language is actually:pt\n",
      "12/01/2021, 22:56:35 - this user is not you! you: zolpidembot VS the tweeter: itsmecapituu, that s great\n",
      "12/01/2021, 22:56:35 - retweeting ←←←←←←←←←←←←←\n",
      "12/01/2021, 22:56:36 - →→→→→→→→→→→→→ retweeted\n",
      "12/01/2021, 22:56:36 - VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now\n",
      "12/01/2021, 22:56:36 - \n",
      "\n",
      "function>>>>>exporting_infos_to_csv\n",
      "12/01/2021, 22:56:36 - today's CSV path: C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\exported_data\\dados_12-01-2021.csv\n",
      "12/01/2021, 22:56:36 - valid_tweet : {'created_at': ['2021-01-13 01:54:23'], 'tweet_ID': ['1349172914650816514'], 'user': ['itsmecapituu'], 'tweet_content': ['Será que tomar dois zolpidem, alprazolam e 200mg de sertralina da ruim?'], 'place': ['None'], 'language': ['pt'], 'source': ['iphone']}\n",
      "12/01/2021, 22:56:36 - dict_values_in_list_version: ['2021-01-13 01:54:23', \"'1349172914650816514\", 'itsmecapituu', 'Será que tomar dois zolpidem, alprazolam e 200mg de sertralina da ruim?', 'None', 'pt', 'iphone']\n",
      "12/01/2021, 22:56:36 - writing tweet details on CSV file\n",
      "12/01/2021, 22:56:36 - \n",
      "\n",
      "function>>>>>write_json_and_updates_value\n",
      "12/01/2021, 22:56:36 - same date!! so, just change the value of tweetts\n",
      "12/01/2021, 22:56:36 - increases both keys , the including failure and the sucessed amounts\n",
      "12/01/2021, 22:56:36 - Waiting 2 min for retrieve another tweet cuz we like safety\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-c1c6e503206b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-212-6a16a0ab6aa7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Waiting 2 min for retrieve another tweet cuz we like safety\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sleep 2 min, so we dont reach the limit 100 tweets per hour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import tweepy\n",
    "import time\n",
    "from datetime import date, datetime \n",
    "import os\n",
    "import pymsgbox \n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
